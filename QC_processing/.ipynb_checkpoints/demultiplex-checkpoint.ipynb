{
 "metadata": {
  "name": "",
  "signature": "sha256:eba94306f718c2241bde9c70ce93cf8677944fd011ebe6d3efea10b53c8e8c07"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook is used to demultiplex the sequencing run into the corresponding samples, according to their barcodes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Imports all the necessary programs\n",
      "# screed for making databases\n",
      "# pandas, which is a library of Python data analysis functions\n",
      "# Counter tool for convenient and rapid tallies\n",
      "# matplotlib for plotting\n",
      "# numpy for basic computing in Python\n",
      "# mpltools are more tools for matplotlib\n",
      "import screed\n",
      "import pandas as pd\n",
      "from collections import Counter\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "from mpltools import style"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/opt/virt_env/lib/python2.7/site-packages/mpltools/style/__init__.py:42: FutureWarning: \n",
        "\n",
        "    The style-sheet functionality in mpltools has been integrated into\n",
        "    Matplotlib >= 1.4. This module will be removed in a future release.\n",
        "\n",
        "    Note that style-sheets used by `matplotlib.style` use the standard\n",
        "    Matplotlib rc-file syntax instead of the INI format used by `mpltools`.\n",
        "    This mostly means un-quoting strings and changing '=' to ':'.\n",
        "\n",
        "\n",
        "  \"\"\", FutureWarning)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sets our style parameters to ggplot\n",
      "style.use(\"ggplot\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tells the notebook to show the output (graphics) from matplotlib inline (in the notebook)\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This step unzips our index read fastq files.\n",
      "!pigz -k -d -p 2 ./SeqData/20150624_I1_001.fastq.gz\n",
      "# -k means keep the original, -d means decompress the input, -p means use this number of processors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This creates the database which it will query\n",
      "# The database will have the sequence name, description, quality, and sequence itself (if those data are in the original files)\n",
      "# The output will be the same file with NAME_screed\n",
      "screed.read_fastq_sequences(\"./SeqData/index_read_1.fq\")\n",
      "screed.read_fastq_sequences(\"./SeqData/index_read_2.fq\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tells the notebook where our index reads are\n",
      "# This used to have .gz at the end of the fastq files\n",
      "# but I feel like we should unzip them before putting them into the DB.\n",
      "# So, I added the unzipping step above.\n",
      "ir1 = \"./SeqData/index_read_1.fq\"\n",
      "ir2 = \"./SeqData/index_read_2.fq\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Takes our index reads and turns them into databases using Screed\n",
      "ir1db = screed.ScreedDB(ir1)\n",
      "ir2db = screed.ScreedDB(ir2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Troubleshooting\n",
      "record=ir1db[ir1db.keys()[14]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Troubleshooting\n",
      "record['sequence']\n",
      "# This is not the right index, but it is what is in the index file."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Troubleshooting\n",
      "f=open(\"./SeqData/read1.fq\")\n",
      "lines = f.readlines()\n",
      "print lines[1:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# locating the tab delimited file with the index reads and the sample IDS\n",
      "# Note that 0,1,2,3,4 are just row numbers\n",
      "# I need to make this file in excel\n",
      "# This step is making that information into a data frame (using panda), called df_map\n",
      "# Note that the first items are identified by a \"0\" (Python uses a 0-index)\n",
      "# Also note that the first column was made up by the program - not present in the initial file.\n",
      "df_map = pd.read_csv(\"./SeqData/INDEX.txt\", delimiter=\"\\t\", usecols=[0,1,2], names=[\"i1\",\"i2\",\"SampleID\"])\n",
      "# prints the head of the dataframe we made called df_map\n",
      "df_map[1:9]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This is making ...\n",
      "# map calls a function (lambda) for a sequence of items (zipped)\n",
      "# lambda creates a function, into which x is input. \n",
      "# Here, we are getting whatever x was at 0, 1, and 2 (so the first three columns of our data), and adding the first two\n",
      "# together (our indicies), and maintaining the second one (our sample IDs).\n",
      "# \"Zipping\" links together three elements of the same length, effectively creating an array of vectors\n",
      "# So, here, we have linked together the columns in our mapping dataframe, df_map.\n",
      "# Basically, we link together the three columns, using zip, and then we concatenate the first two values\n",
      "# at each place and keep the last one separate, using the lambda function we created here.\n",
      "# This happens using the map function - the function called is defined by lambda, the sequence of items we look at \n",
      "# is defined by the zip function\n",
      "# Dict is a data structure in Python, the \"dictionary\"\n",
      "# A dictionary has unique keys that are linked to other data\n",
      "# Here we are using our map output to make the dictionary. The map created two values - our combined indicies and ID.\n",
      "# Thus, the map_d.keys at a given position will be the combined index primers,\n",
      "# and the map_d returned when the map_d.keys at a given position is input, will be our sample ID.\n",
      "map_d = dict(map(lambda x: (x[0] + x[1], x[2]), zip(df_map.i1, df_map.i2, df_map.SampleID)))\n",
      "print map_d.keys()[100], map_d[map_d.keys()[100]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# I should already have the output from this in the folder from our pear_merged data activity from before.\n",
      "screed.read_fastq_sequences(\"./SeqData/pear_merged-2014-03-25.assembled.fastq\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Creates the screed database\n",
      "db = screed.ScreedDB(\"./SeqData/pear_merged-2014-03-25.assembled.fastq_screed\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Re-started at 11:32 PM, finished by 4:20AM\n",
      "# I shouldn't've stopped it - it was probably running fine. So long as there is a star, it is working\n",
      "# The \"Kernel busy\" message button just shows up the first time you start the process. If you reload, it doesn't reappear.\n",
      "\n",
      "# Did a bunch of troubleshooting, figured some things out, probably was all fine, maybe had index reads in wrong order\n",
      "# In a short trial, generated 17% rejected reads (not 100% match). This is fine, probably. After all, there are 16M seqs.\n",
      "# That rate would leave about 13.7M sequences. Then, more QC after that.\n",
      "# Re-started to run again at 6:20AM, finished by 8:15AM.\n",
      "\n",
      "# Sets a counting index and starts the number of unassigned reads at zero.\n",
      "# Defines our output as our fastq file.\n",
      "# Sets up a counter function, which is actually like a dictionary.\n",
      "counter = 0\n",
      "unassigned = 0\n",
      "cnt = Counter()\n",
      "fn = \"./SeqData/pear_merged-2014-03-25.assembled.demult.fastq\"\n",
      "# I think we open up a new file, created, as we called it under fn, [What is \"w\"? \"w\" means we are opeing the file to \"w\"rite]\n",
      "with open(fn, \"w\") as out:\n",
      "    # for each record in our database that we go through iteratively...\n",
      "  for rec in db.itervalues(): \n",
      "        # We make a concatenated index of the ir1db and ir2db that we made earlier, joining the name and sequence\n",
      "        index_concat = ir1db[rec[\"name\"]][\"sequence\"] + ir2db[rec[\"name\"]][\"sequence\"]\n",
      "        # We create a new name from our map_d file created above (the dictionary) using the dictionary to look up what\n",
      "        # it should be called, based on an input of this new name we made (making sure it's all lowercase)\n",
      "        # This should spit out the ID of the sample associated with these indicies, which we then join to\n",
      "        # an underscore, and the current counter value (which number sequence is this?)\n",
      "        try:\n",
      "            new_name = map_d[index_concat] + \"_\" + str(counter) #case sensitive\n",
      "            # If we couldn't find the index name in our dictionary map file, we say it was unassigned, and tally it.\n",
      "        except KeyError:\n",
      "            unassigned += 1\n",
      "            continue\n",
      "            # Resetting to continue\n",
      "        counter += 1\n",
      "        # map_d[index_etc.lower] should give us the sample name we assigned to that index set.\n",
      "        # We feed that into the counter - not quite sure what happens\n",
      "        # We also increase [what?] by 1.\n",
      "        cnt[map_d[index_concat]] += 1 #case sensitive\n",
      "        # We define s and q as the sequecnce and accuracy values (from screed?) \n",
      "        s, q = rec[\"sequence\"], rec[\"accuracy\"]\n",
      "        # The output written to the file we called fn will be all this..not quite sure what's going on.\n",
      "        out.write(\"@%s orig_name=%s\\n%s\\n+\\n%s\\n\"%(new_name,rec[\"name\"],s,q))\n",
      "        # Reports how many reads didn't match the mapping file. Note that we require an exact match here.\n",
      "print \"Unable to assign %s reads to samples\"%unassigned\n",
      "# The final output should be still a fastq file but now with the sample ID attached.\n",
      "# For now it is called pear_merged-2014-03-25.assembled.demult.fastq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Makes a plot of read counts organized by index\n",
      "# Seems like it worked okay - lowest 12 reads <50,000 counts.\n",
      "X = np.arange(len(cnt.keys()))\n",
      "Y = [v for k, v in cnt.most_common()]\n",
      "fig = plt.figure()\n",
      "fig.set_size_inches((18,8))\n",
      "ax = fig.add_subplot(111)\n",
      "bars = ax.bar(X, Y, width=0.5)\n",
      "xlims = ax.set_xlim((X.min(), X.max()))\n",
      "xt = ax.set_xticks(X)\n",
      "\n",
      "xtl = ax.set_xticklabels([k for k, v in cnt.most_common()], rotation=90, ha=\"center\", size=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}